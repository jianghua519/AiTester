# 自动化测试平台存储设计方案

**版本**: 1.0  
**日期**: 2026-02-02  
**作者**: Manus AI

## 1. 引言

本文档为 AI 驱动的自动化测试平台提供一个详细、分层且经济高效的存储设计方案。一个合理的存储架构是确保平台数据安全、系统高性能和未来可扩展性的基石。本设计旨在平衡性能、成本、可靠性和运维复杂性,为不同类型的数据选择最合适的存储解决方案。

## 2. 数据分类与需求分析

在设计存储架构之前,首先需要对平台产生和使用的所有数据进行分类,并分析其独特的访问模式和存储需求。我们将平台数据分为以下七大类:

### 2.1 数据分类总览

| 数据类别 | 描述与示例 | 数据特征 | 访问模式 | 一致性要求 |
| :--- | :--- | :--- | :--- | :--- |
| **核心元数据** | 用户、项目、测试用例、测试套件、测试计划、权限等 | 结构化、小体积、高价值 | 频繁读写、更新密集 | **强一致性** |
| **执行结果数据** | 测试运行历史、每个用例的通过/失败状态、耗时 | 结构化、高增长、时间序列 | 写入密集、查询分析密集 | **强一致性** |
| **测试产物** | 截图 (.png)、录屏 (.mp4)、详细日志 (.log) | 非结构化、大文件、体积增长快 | 写入密集、读取不频繁 | **最终一致性** |
| **缓存数据** | 用户会话、热点数据(如项目列表)、临时计算结果 | 键值对、易失性、小体积 | 极高频读写、低延迟要求 | **无要求** |
| **消息队列数据** | 测试执行任务、结果回传消息 | 瞬时、先进先出 (FIFO) | 极高吞吐量 | **最终一致性** |
| **审计日志** | 用户操作记录(谁、何时、做了什么) | 结构化、不可变、仅追加 | 写入密集、读取稀疏 | **强一致性** |
| **AI 相关数据** | 提示词模板、缓存的 LLM 响应、微调数据集 | 混合类型(文本、文件) | 读密集 | **最终一致性** |

### 2.2 各类数据存储需求详解

#### **核心元数据 (Core Metadata)**
- **需求**: 这部分是系统的“骨架”,任何丢失或不一致都将导致系统瘫痪。因此,需要极高的**数据持久性**和**事务完整性 (ACID)**。读写性能需满足前端 UI 的流畅交互,但通常不会成为系统的主要瓶颈。
- **关键指标**: `Durability`, `ACID Compliance`, `Low Latency`。

#### **执行结果数据 (Execution Results)**
- **需求**: 这是平台增长最快的数据之一。每次测试执行都会产生大量的状态记录。存储系统需要能够处理**高并发写入**,并为后续的报告和仪表盘提供高效的**复杂查询和聚合分析**能力。数据同样需要强一致性以保证报告的准确性。
- **关键指标**: `High Write Throughput`, `Efficient Query & Aggregation`, `Scalability`。

#### **测试产物 (Test Artifacts)**
- **需求**: 这部分数据占据最大的存储空间。单个视频文件可能达到几十兆。存储系统必须具备**高吞吐量的写入能力**和**低成本的存储扩展性**。由于这些文件通常只在测试失败时被查看,读取频率较低,因此对读取延迟不敏感。
- **关键指标**: `High Write Throughput`, `Low Cost per GB`, `High Scalability`。

#### **缓存数据 (Cache Data)**
- **需求**: 缓存的目的是加速前端响应和减轻主数据库的压力。因此,对**读写延迟**的要求是所有数据类型中最高的,必须在毫秒甚至亚毫秒级别。数据是易失的,即使丢失也可以从主数据库重建,因此对持久性无要求。
- **关键指标**: `Ultra-low Latency`, `High IOPS`。

#### **消息队列数据 (Message Queue Data)**
- **需求**: 作为服务间异步通信的桥梁,消息队列需要处理海量的瞬时消息,必须具备**极高的吞吐量**和**低延迟**。它需要保证消息至少被传递一次(At-least-once Delivery),但对长期持久化无要求。
- **关键指标**: `High Throughput`, `Low Latency`, `Reliable Delivery`。

#### **审计日志 (Audit Logs)**
- **需求**: 出于安全和合规要求,审计日志必须是**不可变的 (Immutable)**,只能追加,不能修改或删除。需要保证极高的持久性,并且在需要时能够方便地查询和导出。
- **关键指标**: `Immutability`, `High Durability`, `Efficient Filtering`。

通过以上分析,我们为不同数据类型建立了清晰的需求画像,这将直接指导下一章节的存储技术选型和架构设计。


## 3. 存储架构与技术选型

基于上一章的需求分析,我们设计了一个分层的混合存储架构,为每一类数据匹配最优的存储技术。

### 3.1 整体存储架构图

![存储架构图](/home/ubuntu/storage_architecture.png)

### 3.2 技术选型与理由

| 数据类别 | 选用技术 | 部署模式 | 选型理由 |
| :--- | :--- | :--- | :--- |
| **核心元数据 & 执行结果** | **PostgreSQL** | 主从复制 (Master-Replica) | PostgreSQL 提供了强大的事务支持和复杂查询能力,完全满足元数据和结果数据的强一致性与分析需求。主从模式实现了高可用和读写分离,提升了读取性能。 |
| **测试产物** | **MinIO** | 分布式集群 | MinIO 是兼容 S3 API 的高性能对象存储,非常适合存储大量的非结构化文件。其分布式模式提供了水平扩展能力和数据冗余,成本远低于传统文件系统。 |
| **缓存 & 消息队列** | **Redis** | 哨兵集群 (Sentinel Cluster) | Redis 是业界标准的内存数据库,提供亚毫秒级的延迟,完美匹配缓存和消息队列的性能要求。哨兵模式提供了自动故障转移能力,保证了这两个关键组件的高可用性。 |
| **审计日志** | **Loki** | 集群模式 | Loki 是一个为日志设计的、高度优化的存储系统。它将日志内容存储在对象存储(如 MinIO)中,仅索引元数据,极大地降低了存储成本。其 LogQL 查询语言能高效地进行日志筛选和分析。 |

### 3.3 容量规划

容量规划是一个基于假设和预估的动态过程。以下是一个基于中等规模企业(约 100 名工程师,每天运行 10,000 次测试)在第一年的增长模型。

#### **PostgreSQL 容量估算**

- **假设**:
  - 100 个项目, 5,000 个测试用例。
  - 每天 10,000 次测试运行,每次运行产生 10 个结果记录。
  - 平均每个记录大小为 2 KB。
- **计算**:
  - 每日增长: `10,000 * 10 * 2 KB = 200 MB`
  - 第一年增长: `200 MB/天 * 365 天 ≈ 73 GB`
  - 考虑到索引和系统开销 (约 30%),总计: `73 GB * 1.3 ≈ 95 GB`
- **规划**: 初始分配 **256 GB** 的 SSD 存储,并设置监控告警,当使用率超过 75% 时进行扩容。

#### **MinIO 容量估算**

- **假设**:
  - 每天 10,000 次测试运行。
  - 10% 的测试会失败并产生截图和日志。
  - 1% 的测试会产生录屏视频。
  - 平均大小: 截图 500 KB, 日志 100 KB, 视频 10 MB。
- **计算**:
  - 每日增长: `(10,000 * 10% * (500+100)KB) + (10,000 * 1% * 10MB) = 600 MB + 1000 MB = 1.6 GB`
  - 第一年增长: `1.6 GB/天 * 365 天 ≈ 584 GB`
- **规划**: 初始分配 **2 TB** 的分布式对象存储空间。由于对象存储的扩展非常方便,可以根据实际增长情况动态增加节点。

#### **Redis 容量估算**

- **假设**:
  - 缓存: 缓存 10,000 个热点对象,平均大小 5 KB。
  - 消息队列: 高峰期积压 100,000 条消息,平均大小 2 KB。
- **计算**:
  - 缓存占用: `10,000 * 5 KB = 50 MB`
  - 队列占用: `100,000 * 2 KB = 200 MB`
  - 总计: `250 MB`
- **规划**: 考虑到内存碎片和高可用性(主备),初始分配 **2 GB** 的内存,并配置哨兵集群。

#### **Loki 容量估算**

- **假设**:
  - 每天产生 20 GB 的原始日志。
  - Loki 的索引与数据比例约为 1:10。
- **计算**:
  - 每日索引增长: `20 GB * 10% = 2 GB`
  - 每日对象存储增长: `20 GB` (日志本身存储在 MinIO 中)
- **规划**: Loki 的索引存储分配 **512 GB** SSD。日志数据将复用 MinIO 的存储池,并配置独立的生命周期策略。

### 3.4 数据生命周期管理

为了控制成本和保持性能,必须对不同数据实施生命周期管理策略。

- **执行结果**: 在 PostgreSQL 中保留最近 90 天的详细结果。超过 90 天的结果可以归档到成本更低的对象存储中(如 Parquet 格式),或进行聚合后删除。
- **测试产物**: 在 MinIO 中保留最近 30 天的产物。超过 30 天的产物可以自动删除,或转移到更低成本的归档存储层(如 AWS Glacier)。
- **审计日志**: 根据合规要求,可能需要保留 1 年或更长时间。可以使用 Loki 的多租户功能或 MinIO 的分桶策略进行管理。


## 4. 备份恢复与性能优化

### 4.1 备份与恢复策略

数据安全是平台的生命线。我们为不同存储系统制定了差异化的备份策略,以在成本和恢复能力之间取得平衡。

#### **恢复目标 (RPO & RTO)**

- **恢复点目标 (RPO)**: 系统在发生故障后,可以接受丢失多长时间的数据。
  - **核心元数据 (PostgreSQL)**: **5 分钟**。这是最关键的数据,丢失代价极高。
  - **测试产物 (MinIO)**: **24 小时**。产物数据重要性次之,可以接受一天的数据丢失。
- **恢复时间目标 (RTO)**: 系统在发生故障后,需要在多长时间内恢复服务。
  - **整体平台**: **2 小时**。这是业务可以容忍的最大停机时间。

#### **具体备份方案**

| 存储系统 | 备份工具 | 备份策略 | 频率 |
| :--- | :--- | :--- | :--- |
| **PostgreSQL** | **pgBackRest** | **物理备份 + WAL 归档**。提供时间点恢复 (PITR) 能力。 | **全量备份**: 每周一次; **增量备份**: 每天一次; **WAL 归档**: 实时。 |
| **MinIO** | **MinIO Client (mc)** | **镜像同步 (Mirroring)**。将整个存储桶实时或定期同步到异地灾备集群。 | **实时** (如果网络允许) 或 **每小时一次**。 |
| **Redis** | **RDB + AOF** | **RDB 快照** 用于快速恢复,**AOF (Append-Only File)** 用于最大程度减少数据丢失。 | **RDB**: 每小时一次; **AOF**: 每秒同步一次 (fsync every second)。 |
| **Loki** | (复用 MinIO) | Loki 的数据存储在 MinIO 中,因此其备份策略与 MinIO 一致。索引数据可以根据需要重建。 | 同 MinIO。 |

#### **灾难恢复 (DR) 计划**

1.  **宣告灾难**: 当主站点发生不可逆转的故障(如机房断电、大规模硬件损坏)时,由运维负责人宣告启动 DR 计划。
2.  **启动备用站点**: 在异地灾备中心,启动 Kubernetes 集群和所有应用服务。
3.  **恢复数据**: 
    - 使用 pgBackRest 将 PostgreSQL 恢复到最近的可用时间点。
    - 将 MinIO 的流量切换到灾备集群。
    - 从 RDB 文件恢复 Redis 集群。
4.  **更新 DNS**: 将所有服务的 DNS 记录指向备用站点的入口 IP。
5.  **验证服务**: 对平台进行健康检查,确认所有功能正常后,正式对外提供服务。

### 4.2 性能优化策略

#### **PostgreSQL 优化**

- **索引策略**: 为所有外键和经常用于 `WHERE`, `JOIN`, `ORDER BY` 子句的列创建索引。定期使用 `pg_stat_statements` 分析慢查询并优化索引。
- **查询优化**: 避免 `SELECT *`,只选择需要的列。对于复杂报表,使用物化视图 (Materialized View) 预先计算结果。
- **连接池**: 在应用服务(如 Test Management Service)中使用 PgBouncer 或内置的连接池,复用数据库连接,减少连接开销。
- **读写分离**: 对于报表生成等读密集型任务,将查询路由到只读副本 (Replica),减轻主库 (Master) 的压力。

#### **MinIO 优化**

- **CDN 集成**: 对于需要频繁访问的测试产物(如在线查看报告中的截图),可以在 MinIO 前端集成一个 CDN (如 Cloudflare),利用其边缘节点缓存,加速全球访问。
- **负载均衡**: 在 MinIO 的 Gateway 层前部署负载均衡器,将读写请求分发到不同的节点。

#### **Redis 优化**

- **内存管理**: 启用 `maxmemory-policy` (如 `allkeys-lru`),在内存达到上限时自动淘汰最近最少使用的数据。
- **大 Key 拆分**: 避免在 Redis 中存储过大的 Key-Value 对(如超过 100KB)。对于大的对象,可以将其拆分为多个小的 Key-Value,或将其存储在 MinIO 中,仅在 Redis 中缓存其元数据和路径。
- **持久化调优**: 在性能和数据安全之间权衡。对于纯缓存场景,可以关闭持久化以获得最高性能。对于消息队列,使用 AOF `everysec` 模式是最佳实践。

### 4.3 成本控制策略

- **存储分层**: 积极利用 MinIO 的生命周期管理功能,将超过 30 天的冷数据自动迁移到成本更低的存储层(如 AWS S3 Standard-IA 或 Glacier)。
- **数据压缩**: 对 PostgreSQL 中的大文本字段和 MinIO 中存储的日志文件启用透明压缩,可以显著减少存储空间占用。
- **资源监控与回收**: 定期运行脚本,清理孤立的测试产物(即在数据库中已无记录但仍在对象存储中存在的文件),回收存储空间。

## 5. 总结

本存储设计方案通过对数据进行精细分类,为不同类型的数据匹配了最优的存储技术,实现了性能、成本和可靠性的平衡。通过详细的容量规划、周密的备份恢复策略和多维度的性能优化措施,本方案为构建一个稳定、高效、可扩展的 AI 自动化测试平台奠定了坚实的数据基础。
